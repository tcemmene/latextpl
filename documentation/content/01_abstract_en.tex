\section*{Abstract}
%Processing of acoustic signals is often accompanied by adaptive filtering and parameter adjustments in order to achieve optimal audio quality for a specific task. In terms of hearing aids, an optimal speech intelligibility is intended. Different acoustic scenes or surrounding soundscapes force the speech intelligibility into divergence. Since these factors are constantly changing, adjustments in filter parameters for hearing devices have to be executed in real time. We introduce a system which is able to recognize acoustic environments continuously using a Deep \ac{CNN} and present a realization concept as a fixed-point software implementation.

%Therefore, we created an own dataset


Processing of acoustic signals is often accompanied by adaptive filtering and parameter adjustments in order to achieve optimal audio quality for specific tasks. In terms of hearing aids, the intention is an optimal speech intelligibility and environmental audio perception. Since acoustic scenes and soundscapes are constantly changing during operation, adjustments in  parameters for hearing devices have to be executed in real-time. We introduce a system which is able to continuously recognize acoustic environments using \ac{AI} in the form of a Deep \ac{CNN} with focus on real-time implementation. Inspired by VGGNet-16, the \ac{CNN} architecture was modified to a multi-label multi-output model which is able to predict combinations of scene and soundscape labels simultaneously while sharing the same feature extraction. For training we acquired a custom dataset consisting of 23.8h of high-quality binaural audio data including five classes per label which are clearly distinguishable by humans. Using a manual Grid Search method, we were able to optimize three models with respect to different complexity metrics for choosing a trade-off between accuracy and throughput. \acp{CNN} were then post-quantized to 8-bit which achieved an overall accuracy of 99.07$\%$ in the best case. After reducing the number of \ac{MAC} operations by a factor 154x and parameters by 18x, the classifier was still able to detect scenes and soundscapes with an acceptable accuracy of 94.82$\%$ which allows real-time inference at the edge on discrete low-cost hardware with a clock speed of 10 MHz and one inference per second.